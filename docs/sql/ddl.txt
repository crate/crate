.. highlight:: psql
.. _sql_ddl:

===============
Data Definition
===============


Table Basics
============

To create a table use the ``CREATE TABLE`` command. You must at least specify a name for the
table and names and types of the columns.
See :ref:`sql_ddl_datatypes` for information about the supported data types.

Let's create a simple table with two columns of type ``integer`` and ``string``::

    cr> create table my_table (
    ...   first_column integer,
    ...   second_column string
    ... );
    CREATE OK (... sec)

A table can be removed by using the ``DROP TABLE`` command::

    cr> drop table my_table;
    DROP OK (... sec)

The ``DROP TABLE`` command takes the optional clause ``IF EXISTS`` which prevents the generation
of an error if the specified table does not exist::

    cr> drop table if exists my_table;
    DROP OK (... sec)

Schemas
-------

Tables can be created in different schemas. These are created implicitly on
table creation and cannot be created explicitly. If a schema did not exist yet,
it will be created::

    cr> create table my_schema.my_table (
    ...   pk int primary key,
    ...   label string,
    ...   position geo_point
    ... );
    CREATE OK (... sec)

::

    cr> select schema_name, table_name from information_schema.tables
    ... where table_name='my_table';
    +-------------+------------+
    | schema_name | table_name |
    +-------------+------------+
    | my_schema   | my_table   |
    +-------------+------------+
    SELECT 1 row in set (... sec)

The following schema names are reserved and may not be used:

        * blob
        * information_schema
        * sys

.. note::

   Schemas are primarily namespaces for tables. There is no notion of
   access control. Everybody can see and manipulate tables in every schema.

A user created schema exists as long as there are tables with the same
schema name. If the last table with that schema is dropped,
the schema is gone (except for the ``blob`` and ``doc`` schema)::

    cr> drop table my_schema.my_table ;
    DROP OK (... sec)

Every table that is created without an explicit schema name, will be created in
the ``doc`` schema::

    cr> create table my_doc_table (
    ...   a_column byte,
    ...   another_one geo_point
    ... );
    CREATE OK (... sec)

::

    cr> select schema_name, table_name from information_schema.tables
    ... where table_name='my_doc_table';
    +-------------+--------------+
    | schema_name | table_name   |
    +-------------+--------------+
    | doc         | my_doc_table |
    +-------------+--------------+
    SELECT 1 row in set (... sec)


.. _sql_ddl_naming_restrictions:

Naming restrictions
-------------------

Table, schema and column identifiers cannot have the same names as reserved
key words. Please refer to the :doc:`reference/lexical_structure` section for
more information about naming.

Additionally, table and schema names are restricted in terms of
characters and length. They:

  - may not contain one of the following characters: ``\ / * ? " < > |
    <whitespace> , #``

  - may not contain upper case letters

  - may not *start* with an underscore: ``_``

  - should not exceed 255 bytes when encoded with ``utf-8`` (this
    limit applies on the optionally schema-qualified table name)

Column names are restricted in terms of characters. They:

  - may not contain one of the following characters: ``[`` ``'`` ``]`` ``.``

  - may not *start* with an underscore: ``_``


.. _sql-ddl-generated-columns:

Generated Columns
=================

It is possible to define columns whose value is computed by
applying a *generation expression* in the context of the current row, where
it is possible to reference the values of other columns.

Generated columns are defined by providing a *generation expression*.
Providing a data type is optional. It is inferred by the return type of the supplied
expression if omitted::

    cr> CREATE TABLE computed (
    ...   dividend double,
    ...   divisor double,
    ...   quotient AS (dividend / divisor)
    ... );
    CREATE OK (... sec)

For a full syntax description, see :ref:`ref-create-table`.

Generated columns are read-only as they are computed internally.
They are computed upon ``INSERT`` and ``UPDATE``::

    cr> INSERT INTO computed (dividend, divisor) VALUES (1.7, 1.5), (0.0, 10.0);
    INSERT OK, 2 rows affected (... sec)

.. Hidden: Refresh::

    cr> refresh table computed;
    REFRESH OK (... sec)

The generated column is now filled with the computed value::

    cr> SELECT dividend, divisor, quotient
    ... FROM computed
    ... ORDER BY quotient;
    +----------+---------+--------------------+
    | dividend | divisor |           quotient |
    +----------+---------+--------------------+
    |      0.0 |    10.0 | 0.0                |
    |      1.7 |     1.5 | 1.1333333333333333 |
    +----------+---------+--------------------+
    SELECT 2 rows in set (... sec)

If values are supplied for generated columns, these values are validated
against the result of applying the *generation expression*::

    cr> INSERT INTO computed (dividend, divisor, quotient) VALUES (100.0, 2.0, 12.0);
    SQLActionException[SQLParseException: Given value 12.0 for generated column does not match defined generated expression value 50.0]


.. warning::

    Supplied values for generated columns are not validated when they
    are imported using ``copy from``.

They can also be used in the :ref:`partitioned_by_clause` in order to
compute the value to partition by from existing columns in the table::

    cr> CREATE TABLE computed_and_partitioned (
    ...   huge_cardinality long,
    ...   big_data string,
    ...   partition_value AS ( huge_cardinality % 10 )
    ... ) PARTITIONED BY (partition_value);
    CREATE OK (... sec)

.. Hidden: drop tables::

    cr> drop table my_doc_table;
    DROP OK (... sec)
    cr> DROP TABLE computed;
    DROP OK (... sec)
    cr> DROP TABLE computed_and_partitioned;
    DROP OK (... sec)



Constraints
===========

Primary Key
-----------

The primary key constraint combines a unique constraint and a not-null constraint. It also defines
the default routing value used for sharding. Example::

    cr> create table my_table1 (
    ...   first_column integer primary key,
    ...   second_column string
    ... );
    CREATE OK (... sec)

Currently primary keys cannot be auto generated and have to be specified if
data is inserted, otherwise an error is returned.

Defining multiple columns with a primary key constraint is also supported::

    cr> create table my_table1pk (
    ...   first_column integer primary key,
    ...   second_column string primary key,
    ...   third_column string
    ... );
    CREATE OK (... sec)

Or using a alternate syntax::

    cr> create table my_table1pk1 (
    ...   first_column integer,
    ...   second_column string,
    ...   third_column string,
    ...   primary key (first_column, second_column)
    ... );
    CREATE OK (... sec)

.. note::

    Not all column types can be used as PRIMARY KEY. See :ref:`primary_key_constraint`.

.. _sql_ddl_sharding:

Sharding
========

Number of Shards
----------------

Crate supports sharding natively, it even uses *5* shards by default if not further defined.
The number of shards can be defined by using the ``CLUSTERED INTO <number> SHARDS`` statement on
table creation. Example::

    cr> create table my_table5 (
    ...   first_column int
    ... ) clustered into 10 shards;
    CREATE OK (... sec)

.. note::

  The number of shards can only be set on table creation, it cannot be changed later on.

.. _routing:

Routing
-------

The column used for routing can be freely defined using the ``CLUSTERED BY (<column>)``
statement and is used to route a row to a particular shard. Example::

    cr> create table my_table6 (
    ...   first_column int,
    ...   second_column string
    ... ) clustered by (first_column);
    CREATE OK (... sec)


If primary key constraints are defined, the routing column definition
can be omitted as primary key columns are always used for routing by default.
If the routing column is defined explicitly, it must match a primary key column::

    cr> create table my_table8 (
    ...   first_column int primary key,
    ...   second_column string primary key,
    ...   third_column string
    ... ) clustered by (first_column);
    CREATE OK (... sec)


Example for combining custom routing and shard definition::

    cr> create table my_table9 (
    ...   first_column int primary key,
    ...   second_column string primary key,
    ...   third_column string
    ... ) clustered by (first_column) into 10 shards;
    CREATE OK (... sec)


.. _replication:

Replication
===========

Replication of a table in Crate means that each primary shard of a
table is stored additionally on so called secondary shards. This might
be useful for better read performance and high availability. If not
specified, crate creates one replica, which means that a tables
content is stored twice across the nodes of a cluster.

Defining the number of replicas is done using the
``number_of_replicas`` property.

Example::

    cr> create table my_table10 (
    ...   first_column int,
    ...   second_column string
    ... ) with (number_of_replicas = 1);
    CREATE OK (... sec)


The `number_of_replicas` property also accepts an string as parameter that
contains a `range`.

A range is a definition of minimum number of replicas to maximum
number of replicas depending on the number of nodes in the
cluster. The table below shows some examples.

===== ======================================================================
Range Explanation
===== ======================================================================
0-1   Will create 0 or 1 replicas depending on the number of available nodes
----- ----------------------------------------------------------------------
2-4   Table requires at least 2 replicas to be fully replicated. Will
      create up to 4 if nodes are added.
----- ----------------------------------------------------------------------
0-all Will expand the number of replicas to the available number of nodes.
===== ======================================================================

For details of the range syntax refer to :ref:`number_of_replicas`.

.. note::

  The number of replicas can be changed at any time.

.. _column_policy:

Column Policy
=============

The Column Policy defines if a table enforces its defined schema or if it's
allowed to store additional columns which are a not defined in the table schema.
If the column policy is not defined within the ``with`` clause, ``dynamic`` will be used.

strict
------

The column policy can be configured to be ``strict``, rejecting any column on
insert/update/copy_to which is not defined in the schema.

Example::

    cr> create table my_table11 (
    ...   title string,
    ...   author string
    ... ) with (column_policy = 'strict');
    CREATE OK (... sec)

.. hide:

    cr> drop table my_table11;
    DROP OK (... sec)

dynamic
-------

The other option is ``dynamic`` which is the default policy.
``dynamic`` means that new columns can be added using ``insert``, ``update`` or ``copy from``.

Note that adding new columns to a table with a ``dynamic`` policy will affect the schema of the
table. Once a column is added, it shows up in the ``information_schema.columns``
table and its type and attributes are fixed. It will have the type that was guessed by its
inserted/updated value and they will always be ``not_indexed`` which means
they are analyzed with the ``plain`` analyzer, which means as-is.
If a new column ``a`` was added with type ``boolean``,
adding strings to this column will result in an error, except
the string can be implicit casted to a ``boolean`` value.

Examples::

    cr> create table my_table12 (
    ...   title string,
    ...   author string
    ... );
    CREATE OK (... sec)

.. hide:

    cr> drop table my_table12;
    DROP OK (... sec)

which is exactly the same as::

    cr> create table my_table13 (
    ...   title string,
    ...   author string
    ... ) with (column_policy = 'dynamic');
    CREATE OK (... sec)

.. hide:

    cr> drop table my_table13;
    DROP OK (... sec)

New columns added to ``dynamic`` tables are, once added, usable as usual 
columns. One can retrieve them, sort by them and use them in where clauses.

.. warning::
    The mapping update is processed asynchrously on multiple nodes. If a new 
    field gets added to the local mapping of two shards, these shards are sending 
    their mapping to the master. If this mapping update gets delivered later 
    than the next query on the previously added column, it will result 
    in a ``ColumnUnknownException``.

.. _sql_ddl_partitioned_by:

Partitioned Tables
==================

A partitioned table is a virtual table that is internally split up into several
internal *tables*, called `partitions`, by the value of one or more columns. For every distinct combination
of values in those configured columns one separate partition is created.

Creating a partitioned table is done using the :ref:`partitioned_by_clause`::

    cr> create table partitioned_table (
    ... id long,
    ... title string,
    ... date timestamp
    ... ) partitioned by (date);
    CREATE OK (... sec)

For further details, please refer to :ref:`partitioned_by_clause`.

.. _fulltext-indices:

.. _indices_and_fulltext:

Indices and Fulltext Search
===========================

Fulltext indices take the contents of one or more fields and split it
up into tokens that are used for fulltext-search. The transformation
from a text to separate tokens is done by an analyzer. In order to
create fulltext search queries a :ref:`fulltext index with an analyzer
<sql_ddl_index_fulltext>` must be defined for the related columns.

.. _sql_ddl_index_definition:

Index Definition
----------------

In Crate, every column's data is indexed using the ``plain`` index
method by default.  Currently there are 3 choices related to index
definition:

  - `Disable indexing`_

  - `Plain index (Default)`_

  - `Fulltext index with analyzer`_

.. warning::

    Creating an index after a table was already created is currently not supported,
    so think carefully while designing your table definition.


.. _sql_ddl_index_off:

Disable indexing
................

Indexing can be turned off by using the ``INDEX OFF`` column
definition. Without an index the column can never be hit by a query,
and is only available as a result column::

    cr> create table my_table1b (
    ...   first_column string INDEX OFF
    ... );
    CREATE OK (... sec)

.. note::

    Operations such as data aggregations (:ref:`sql_dql_aggregation`), grouping
    (:ref:`sql_dql_group_by`), and sorting (:ref:`sql_reference_order_by`)
    only work on indexed fields.

.. _sql_ddl_index_plain:

Plain index (Default)
.....................

An index of type ``plain`` is indexing the input data as-is without
analyzing.  Using the ``plain`` index method is the default behaviour
but can also be declared explicitly::

    cr> create table my_table1b1 (
    ...   first_column string INDEX using plain
    ... );
    CREATE OK (... sec)

This results in the same behaviour than without any index declaration::

    cr> create table my_table1b2 (
    ...   first_column string
    ... );
    CREATE OK (... sec)


.. _sql_ddl_index_fulltext:

Fulltext index with analyzer
............................

By defining an index on a column, it's analyzed data is indexed
instead of the raw data.  Thus, depending on the used analyzer,
querying for the exact data may not work anymore.  See
:ref:`builtin-analyzer` for details about available builtin analyzer
or :ref:`sql-ddl-custom-analyzer`.

If no analyzer is specified when using a fulltext index, the
:ref:`standard <standard-analyzer>` analyzer is used::

    cr> create table my_table1c (
    ...   first_column string INDEX using fulltext
    ... );
    CREATE OK (... sec)

Defining the usage of a concrete analyzer is straight forward by
defining the analyzer as a parameter using the ``WITH`` statement::

    cr> create table my_table1d (
    ...   first_column string INDEX using fulltext with (analyzer = 'english')
    ... );
    CREATE OK (... sec)


Defining a named index column definition
........................................

It's also possible to define an index column which treat the data of a
given column as input.  This is especially useful if you want to
search for both, the exact and analyzed data::

    cr> create table my_table1e (
    ...   first_column string,
    ...   INDEX first_column_ft using fulltext (first_column)
    ... );
    CREATE OK (... sec)

Of course defining a custom analyzer is possible here too::

    cr> create table my_table1f (
    ...   first_column string,
    ...   INDEX first_column_ft
    ...     using fulltext(first_column) with (analyzer = 'english')
    ... );
    CREATE OK (... sec)


.. _sql-ddl-composite-index:

Defining a composite index
..........................

Defining a composite (or combined) index is done using the same syntax
as above despite multiple columns are given to the ``fulltext`` index
method::

    cr> create table documents (
    ...   title string,
    ...   body string,
    ...   INDEX title_body_ft
    ...     using fulltext(title, body) with (analyzer = 'english')
    ... );
    CREATE OK (... sec)

Composite indices can include nested columns within object columns as well::

    cr> create table my_table1g (
    ...   title string,
    ...   author object(dynamic) as (
    ...     name string,
    ...     birthday timestamp
    ...   ),
    ...   INDEX author_title_ft using fulltext(title, author['name'])
    ... );
    CREATE OK (... sec)

.. _sql-ddl-custom-analyzer:

.. _create_custom_analyzer:

Create custom analyzer
----------------------

An analyzer consists of one tokenizer, zero or more token-filters, and
zero or more char-filters.

When a field-content is analyzed to become a stream of tokens, the
char-filter is applied at first.  It is used to filter some special
chars from the stream of characters that make up the content.

Tokenizers split the possibly filtered stream of characters into tokens.

Token-filters can add tokens, delete tokens or transform them to
finally produce the desired stream of tokens.

With these elements in place, analyzers provide finegrained control
over building a token stream used for fulltext search.  For example
you can use language specific analyzers, tokenizers and token-filters
to get proper search results for data provided in a certain language.

.. highlight:: psql

Here is a simple Example::

    cr> create ANALYZER myanalyzer (
    ...   TOKENIZER whitespace,
    ...   TOKEN_FILTERS (
    ...     lowercase,
    ...     kstem
    ...   ),
    ...   CHAR_FILTERS (
    ...     mapping
    ...   )
    ... );
    CREATE OK (... sec)

This creates a custom analyzer called ``myanalyzer``. It uses the built-in
:ref:`whitespace-tokenizer` tokenizer and two built-in token filters.
:ref:`lowercase-tokenfilter` and :ref:`kstem-tokenfilter`, as well as a
:ref:`mapping-charfilter` char-filter.

It is possible to further customize the built-in token filters, char-filters or
tokenizers::

    cr> create ANALYZER myanalyzer_customized (
    ...   TOKENIZER whitespace,
    ...   TOKEN_FILTERS (
    ...     lowercase,
    ...     kstem
    ...   ),
    ...   CHAR_FILTERS (
    ...     mymapping WITH (
    ...       type='mapping',
    ...       mappings = ['ph=>f', 'qu=>q', 'foo=>bar']
    ...     )
    ...   )
    ... );
    CREATE OK (... sec)

This example creates another analyzer. This time called
``myanalyzer_customized``. It uses the same tokenizer and token filters as in
the previous example, but specifies custom options to the
:ref:`mapping-charfilter` char-filter.

The name (``mymapping``) is a custom name which may not conflict with built-in
char-filters or other custom char-filters.

The provided ``type`` property is **required** as it specifies which built-in
char-filter should be customized. The other option ``mappings`` is specific to
the used type/char-filter.

Tokenizer and token-filters can be customized in the same way.

.. note::

    Altering analyzers is not supported yet.

.. seealso::

  :ref:`ref-create-analyzer` for the syntax reference.

  :ref:`builtin-tokenizer` for a list of built-in tokenizer.

  :ref:`builtin-token-filter` for a list of built-in token-filter.

  :ref:`builtin-char-filter` for a list of built-in char-filter.

Extending Bultin Analyzer
-------------------------

Existing Analyzers can be used to create custom Analyzers by means of extending them.

You can extend and parameterize :ref:`builtin-analyzer` like this::

    cr> create ANALYZER "german_snowball" extends snowball WITH (
    ...   language = 'german'
    ... );
    CREATE OK (... sec)

If you extend :ref:`builtin-analyzer`, tokenizer, char-filter or
token-filter cannot be defined.  In this case use the parameters
available for the extended :ref:`builtin-analyzer`.

If you extend custom-analyzers, every part of the analyzer that is
ommitted will be taken from the extended one.  Example::

    cr> create ANALYZER e2 EXTENDS myanalyzer (
    ...     TOKENIZER mypattern WITH (
    ...       type = 'pattern',
    ...       pattern = '.*'
    ...     )
    ... );
    CREATE OK (... sec)

This analyzer will use the char-filters and token-filters from
``myanalyzer`` and will override the tokenizer with ``mypattern``.

Analyzer Reference
------------------

See the reference documentation of the :ref:`builtin-analyzer` to get detailed
information on the available analyzers.


.. _sql_ddl_system_columns:

System Columns
==============

On every table Crate implements several implicitly defined system columns. Their names are
reserved and cannot be used as user-defined column names. All system columns are prefixed with
an underscore.

.. _sql_ddl_system_column_version:

_version
  Crate uses an internal versioning for every row, the version number is increased on every write.
  This column can be used for `Optimistic Concurrency Control`_, see :ref:`sql_occ` for usage
  details.

.. _sql_ddl_system_column_score:

_score
  This internal system column is available on all documents retrieved by a ``SELECT`` query.
  It is representing the scoring ratio of the document related to the used query filter and
  makes most sense on fulltext searches.
  The scoring ratio is always related to the highest score determined by a search,
  thus scores are not directly comparable across searches.
  If the query does not include a fulltext search the value is 1.0f in most cases.

.. _sql_ddl_system_column_id:

_id
  ``_id`` is an internal system column that is available on each indexed document and can be retrieved
  by a ``SELECT`` query from doc schema tables.
  The value is a unique identifier for each row in a table and is a compound string representation of all
  primary key values of that row. If no primary keys are defined the id is randomly generated.
  If no dedicated routing column is defined the ``_id`` value is used for distributing
  the records on the shards.

.. _Optimistic Concurrency Control: http://en.wikipedia.org/wiki/Optimistic_concurrency_control

.. _sql_ddl_alter_table:

Alter Table
===========

Updating Parameters
-------------------

The parameters of a table can be modified using the `ALTER TABLE` clause::

    cr> alter table my_table1 set (number_of_replicas = '0-all');
    ALTER OK (... sec)

In order to set a parameter to its default value use `reset`::

    cr> alter table my_table1 reset (number_of_replicas);
    ALTER OK (... sec)

Read :ref:`Alter Partitioned Tables <partitioned_tables_alter>` to see
how to alter parameters of partitioned tables.

Adding Columns
--------------

In order to add a column to an existing table use ``ALTER TABLE`` with the
``ADD COLUMN`` clause::

    cr> alter table my_table1 add column new_column_name string;
    ALTER OK (... sec)

The inner schema of object columns can also be extended, as shown in the
following example.

First a column of type object is added::

    cr> alter table my_table1 add column obj_column object as (age int);
    ALTER OK (... sec)


And now a nested column named ``name`` is added to the ``obj_column``::

    cr> alter table my_table1 add column obj_column['name'] string;
    ALTER OK (... sec)

::

    cr> select column_name, data_type from information_schema.columns
    ... where table_name = 'my_table1' and column_name like 'obj_%';
    +--------------------+-----------+
    | column_name        | data_type |
    +--------------------+-----------+
    | obj_column         | object    |
    | obj_column['age']  | integer   |
    | obj_column['name'] | string    |
    +--------------------+-----------+
    SELECT 3 rows in set (... sec)

.. _ddl-set-reset:

Set and Reset
=============

The crate cluster can be configured at runtime using the :ref:`SET
<ref-set>` and :ref:`RESET <ref-set>` statement.
See the :ref:`Cluster Settings <conf-cluster-settings>` configuration
section for details about the supported settings.

If :ref:`SET <ref-set>` is used with ``PERSISTENT`` the change will
survive a cluster restart, if used with
``TRANSIENT`` the value will be restored to default or config file
value on a restart::

    cr> SET GLOBAL PERSISTENT stats.enabled = false;
    SET OK (... sec)

::

    cr> select sys.cluster.settings['stats']['enabled'] from sys.cluster;
    +------------------------------------------+
    | sys.cluster.settings['stats']['enabled'] |
    +------------------------------------------+
    | FALSE                                    |
    +------------------------------------------+
    SELECT 1 row in set (... sec)

You can change multiple values at once::

    cr> SET GLOBAL TRANSIENT stats.enabled = true,
    ... stats.jobs_log_size = 1024, stats.operations_log_size = 4096;
    SET OK (... sec)

::

    cr> select settings['stats']['enabled'],
    ...   settings['stats']['jobs_log_size'],
    ...   settings['stats']['operations_log_size']
    ... from sys.cluster;
    +-...------------+-...------------------+-...------------------------+
    | ...['enabled'] | ...['jobs_log_size'] | ...['operations_log_size'] |
    +-...------------+-...------------------+-...------------------------+
    | TRUE           |                 1024 |                       4096 |
    +-...------------+-...------------------+-...------------------------+
    SELECT 1 row in set (... sec)

Its also possible to save a complete nested object of
settings::

    cr> SET GLOBAL TRANSIENT stats = {
    ...   jobs_log_size = 2048,
    ...   operations_log_size = 8192
    ... };
    SET OK (... sec)

::

    cr> select settings['stats'] from sys.cluster;
    +-----------------------------------------------------------------------+
    | settings['stats']                                                     |
    +-----------------------------------------------------------------------+
    | {"enabled": true, "jobs_log_size": 2048, "operations_log_size": 8192} |
    +-----------------------------------------------------------------------+
    SELECT 1 row in set (... sec)

Using the ``RESET`` statement, a setting will be reset to either on
node startup defined configuration file value or to its default value::

    cr> RESET GLOBAL stats.enabled, stats.operations_log_size;
    RESET OK (... sec)

::

    cr> select settings['stats'] from sys.cluster;
    +-------------------------------------------------------------------------+
    | settings['stats']                                                       |
    +-------------------------------------------------------------------------+
    | {"enabled": false, "jobs_log_size": 2048, "operations_log_size": 10000} |
    +-------------------------------------------------------------------------+
    SELECT 1 row in set (... sec)

``RESET`` can also be done on objects::

    cr> RESET GLOBAL stats;
    RESET OK (... sec)

::

    cr> select settings['stats'] from sys.cluster;
    +--------------------------------------------------------------------------+
    | settings['stats']                                                        |
    +--------------------------------------------------------------------------+
    | {"enabled": false, "jobs_log_size": 10000, "operations_log_size": 10000} |
    +--------------------------------------------------------------------------+
    SELECT 1 row in set (... sec)


Show Create Table
=================

.. hide:
    cr> create table if not exists my_table (
    ...   first_column integer primary key,
    ...   second_column string,
    ...   third_column timestamp,
    ...   fourth_column object(strict) as (
    ...     key string,
    ...     value string
    ...   )
    ... ) clustered by (first_column) into 5 shards;
    CREATE OK (... sec)

The ``SHOW CREATE TABLE`` statement can be used to print the DDL statement of
already existing user-created doc tables in the cluster::

    cr> show create table my_table;
    +-----------------------------------------------------+
    | SHOW CREATE TABLE doc.my_table                      |
    +-----------------------------------------------------+
    | CREATE TABLE IF NOT EXISTS "doc"."my_table" (       |
    |    "first_column" INTEGER,                          |
    |    "fourth_column" OBJECT (STRICT) AS (             |
    |       "key" STRING,                                 |
    |       "value" STRING                                |
    |    ),                                               |
    |    "second_column" STRING,                          |
    |    "third_column" TIMESTAMP,                        |
    |    PRIMARY KEY ("first_column")                     |
    | )                                                   |
    | CLUSTERED BY ("first_column") INTO 5 SHARDS         |
    | WITH (                                              |
    |    "blocks.metadata" = false,                       |
    |    "blocks.read" = false,                           |
    |    "blocks.read_only" = false,                      |
    |    "blocks.write" = false,                          |
    |    column_policy = 'dynamic',                       |
    |    number_of_replicas = '1',                        |
    |    "recovery.initial_shards" = 'quorum',            |
    |    refresh_interval = 1000,                         |
    |    "routing.allocation.enable" = 'all',             |
    |    "routing.allocation.total_shards_per_node" = -1, |
    |    "translog.disable_flush" = false,                |
    |    "translog.flush_threshold_ops" = 2147483647,     |
    |    "translog.flush_threshold_period" = 1800000,     |
    |    "translog.flush_threshold_size" = 209715200,     |
    |    "translog.interval" = 5000,                      |
    |    "translog.sync_interval" = 5000,                 |
    |    "unassigned.node_left.delayed_timeout" = 60000,  |
    |    "warmer.enabled" = true                          |
    | )                                                   |
    +-----------------------------------------------------+
    SHOW 1 row in set (... sec)


The table settings returned within the ``WITH`` clause of the result are all
available table settings showing their respective values at the time of the
execution of the ``SHOW`` statement.
Different versions of Crate may have different default table settings. This
means that if you re-create the table using the resulting ``CREATE TABLE``
statement the settings of the 'old' table may differ from the settings of
the 'new' table. This is because the table settings are set explicitly on
creation time.
